{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frper\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import  sklearn.linear_model as linearModel\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import seaborn \n",
    "import matplotlib.pyplot as plt\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "import timeit\n",
    "import pymc3 as pm\n",
    "import matplotlib.lines as mlines\n",
    "from sklearn import svm\n",
    "np.random.seed(1)\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bridgeSampling as bs  # it contains a method to estimate the marginal likelihood according to the Bridge Sampling approach\n",
    "import utilFunctions as ut   # it has different methods to handle and plot data \n",
    "import BayesianModels as bm  # it has methods to build and train bayesian model (Logistic Regression and Neural Nets) \n",
    "import experiments as exp  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running OGLE\n",
      "The dataset contains: 5297 samples\n"
     ]
    }
   ],
   "source": [
    "Data, ID, Class_col, Classes = ut.Initialize(survey='OGLE')\n",
    "PCA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LPV', 'RRLYR', 'CEP', 'DSCT', 'EB'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biased sample:  False\n",
      "alpha:  0.92\n",
      "Drop Easier instances: False\n",
      "Modfied prior False\n",
      "RRLYR DSCT\n",
      "Running Define TrainSet\n",
      "(5297, 62)\n",
      "Test size:  1059\n",
      "Shape training:  (4237, 60)\n",
      "Shape testing:  (1060, 60)\n",
      "Running experiments\n",
      "(4237, 60)\n",
      "(1060, 60)\n",
      "2\n",
      "Index(['class_name', 'PC0', 'PC1'], dtype='object')\n",
      "------- Metropolis--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sequential sampling (2 chains in 1 job)\n",
      "CompoundStep\n",
      ">Metropolis: [PC1]\n",
      ">Metropolis: [PC0]\n",
      ">Metropolis: [Intercept]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 20500/20500 [01:34<00:00, 216.46it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 20500/20500 [01:35<00:00, 214.51it/s]\n",
      "The number of effective samples is smaller than 10% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "20000\n",
      "10000\n",
      "20000\n",
      "20000\n",
      "The Bridge Sampling Estimatation of Logml is -1033.09913\n",
      "return the last model and trace\n",
      "Accuracy train:  0.6606799230275818\n",
      "Accuracy test:  0.6368286445012787\n",
      "Training...\n",
      "Testing...\n",
      "Accuracy train deterministic 0.6574307344597051\n",
      "Accuracy test deterministic 0.6416970310391363\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Biased sample:  False\n",
      "alpha:  0.92\n",
      "Drop Easier instances: False\n",
      "Modfied prior False\n",
      "RRLYR DSCT\n",
      "Running Define TrainSet\n",
      "(5297, 62)\n",
      "Test size:  1059\n",
      "Shape training:  (4237, 60)\n",
      "Shape testing:  (1060, 60)\n",
      "Running experiments\n",
      "(4237, 60)\n",
      "(1060, 60)\n",
      "4\n",
      "Index(['class_name', 'PC0', 'PC1', 'PC2', 'PC3'], dtype='object')\n",
      "------- Metropolis--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sequential sampling (2 chains in 1 job)\n",
      "CompoundStep\n",
      ">Metropolis: [PC3]\n",
      ">Metropolis: [PC2]\n",
      ">Metropolis: [PC1]\n",
      ">Metropolis: [PC0]\n",
      ">Metropolis: [Intercept]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 20500/20500 [02:36<00:00, 130.58it/s]\n",
      " 40%|██████████████████████████████▍                                             | 8196/20500 [01:06<01:40, 122.89it/s]\n",
      "Only one chain was sampled, this makes it impossible to run some convergence checks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "20000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "Error\n",
      "Biased sample:  False\n",
      "alpha:  0.92\n",
      "Drop Easier instances: False\n",
      "Modfied prior False\n",
      "RRLYR DSCT\n",
      "Running Define TrainSet\n",
      "(5297, 62)\n",
      "Test size:  1059\n",
      "Shape training:  (4237, 60)\n",
      "Shape testing:  (1060, 60)\n",
      "Running experiments\n",
      "(4237, 60)\n",
      "(1060, 60)\n",
      "6\n",
      "Index(['class_name', 'PC0', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5'], dtype='object')\n",
      "------- Metropolis--------\n"
     ]
    }
   ],
   "source": [
    "burn_in_ = 100\n",
    "test = 0.2 \n",
    "obs_fold = 100\n",
    "biased, DropEasy, prior = False, False, False\n",
    "alpha = [0.92]#[0.9+np.round_(i/100,2) for i in range(0,10)]\n",
    "results = []\n",
    "summaryAcurracy = []\n",
    "label1 = Classes[1]\n",
    "label2 = Classes[3]\n",
    "#for (label1, label2) in list(combinations(Classes, 2)): \n",
    "for k in [2, 4, 6]:\n",
    "    for a in alpha:\n",
    "        try:\n",
    "            print('Biased sample: ', biased)\n",
    "            print('alpha: ', a)\n",
    "            print('Drop Easier instances:', DropEasy)\n",
    "            print('Modfied prior', prior)\n",
    "            print(label1, label2)\n",
    "            results_summary, model_ogle, trace, dataTrain, dataTest = exp.runExperiments(Data,  class_1= label1, class_2=label2, components= [k],\n",
    "                                                                                                             method=[7], size=[0.8], ml= True, \n",
    "                                                                                                             fit_iterations= 20000, name_class_col_= Class_col, \n",
    "                                                                                                             id_col_=ID, biasedSplit = biased, \n",
    "                                                                                                             ModifiedPrior = prior, DropEasy_ =  DropEasy, alpha_ = a, \n",
    "                                                                                                            PCA_ = PCA, kernel = False)\n",
    "            label = dataTrain['label']\n",
    "            labelTest = dataTest['label']\n",
    "            del dataTrain['label']\n",
    "            del dataTest['label']\n",
    "\n",
    "            r = ut.get_z(dataTrain, trace = trace, burn_in = 500)\n",
    "            predictions_1_Train = ut.logistic_function_(r).mean(axis=1)>0.5\n",
    "            acc1 = accuracy_score(label, predictions_1_Train, normalize=True)\n",
    "            print('Accuracy train: ', acc1)\n",
    "\n",
    "            r = ut.get_z(dataTest, trace = trace, burn_in = 500)\n",
    "            predictions_1_Test = ut.logistic_function_(r).mean(axis=1)>0.5\n",
    "            acc2 = accuracy_score(labelTest, predictions_1_Test, normalize=True)\n",
    "            print('Accuracy test: ', acc2)\n",
    "\n",
    "\n",
    "\n",
    "            n_split_train = 10 #int(dataTrain.shape[0]/obs_fold)\n",
    "            n_split_test = 10 #int(dataTest.shape[0]/ obs_fold)\n",
    "            clf1 = linearModel.LogisticRegression(C=1.0)\n",
    "            acc_kfold, acc_kfold_Test = ut.KFold(dataTrain, label, dataTest, labelTest, n_split_test, n_split_train, clf1)\n",
    "\n",
    "            print('Accuracy train deterministic', np.mean(acc_kfold))\n",
    "            print('Accuracy test deterministic', np.mean(acc_kfold_Test))\n",
    "            summaryAcurracy.append([k, a, label1, label2, label.shape[0],labelTest.shape[0], results_summary[4][0], acc1, acc2, np.mean(acc_kfold), np.mean(acc_kfold_Test), biased, DropEasy, prior])\n",
    "            print('-----------------------------------------------------------------------------------------------')\n",
    "            results.append([results_summary, accuracy_score(label, predictions_1_Train, normalize=True), accuracy_score(labelTest, predictions_1_Test, normalize=True), np.mean(acc_kfold), np.mean(acc_kfold_Test), acc_kfold, acc_kfold_Test])\n",
    "        except: \n",
    "            print('Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biased sample:  False\n",
      "alpha:  0.92\n",
      "Drop Easier instances: False\n",
      "Modfied prior False\n",
      "VVV_v3_RRc VVV_v3_ELL\n",
      "Running Define TrainSet\n",
      "(10000, 62)\n",
      "Test size:  1999\n",
      "Shape training:  (8000, 60)\n",
      "Shape testing:  (2000, 60)\n",
      "Running experiments\n",
      "(8000, 60)\n",
      "(2000, 60)\n",
      "2\n",
      "Index(['Class', 'PC0', 'PC1', 'PC2', 'PC3'], dtype='object')\n",
      "------- Metropolis--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sequential sampling (2 chains in 1 job)\n",
      "CompoundStep\n",
      ">Metropolis: [PC3]\n",
      ">Metropolis: [PC2]\n",
      ">Metropolis: [PC1]\n",
      ">Metropolis: [PC0]\n",
      ">Metropolis: [Intercept]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 20500/20500 [01:32<00:00, 221.53it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 20500/20500 [01:33<00:00, 219.35it/s]\n",
      "The number of effective samples is smaller than 10% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "20000\n",
      "10000\n",
      "20000\n",
      "20000\n",
      "The Bridge Sampling Estimatation of Logml is -534.43492\n",
      "return the last model and trace\n",
      "Accuracy train:  0.66125\n",
      "Accuracy test:  0.6324324324324324\n",
      "Training...\n",
      "Testing...\n",
      "Accuracy train deterministic 0.6525097671511174\n",
      "Accuracy test deterministic 0.6491228070175439\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Biased sample:  False\n",
      "alpha:  0.92\n",
      "Drop Easier instances: False\n",
      "Modfied prior False\n",
      "VVV_v3_RRc VVV_v3_ELL\n",
      "Running Define TrainSet\n",
      "(10000, 62)\n",
      "Test size:  1999\n",
      "Shape training:  (8000, 60)\n",
      "Shape testing:  (2000, 60)\n",
      "Running experiments\n",
      "(8000, 60)\n",
      "(2000, 60)\n",
      "4\n",
      "Index(['Class', 'PC0', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7'], dtype='object')\n",
      "------- Metropolis--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sequential sampling (2 chains in 1 job)\n",
      "CompoundStep\n",
      ">Metropolis: [PC7]\n",
      ">Metropolis: [PC6]\n",
      ">Metropolis: [PC5]\n",
      ">Metropolis: [PC4]\n",
      ">Metropolis: [PC3]\n",
      ">Metropolis: [PC2]\n",
      ">Metropolis: [PC1]\n",
      ">Metropolis: [PC0]\n",
      ">Metropolis: [Intercept]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 20500/20500 [02:51<00:00, 119.46it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 20500/20500 [02:53<00:00, 118.25it/s]\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "20000\n",
      "10000\n",
      "20000\n",
      "20000\n",
      "The Bridge Sampling Estimatation of Logml is -539.45241\n",
      "return the last model and trace\n",
      "Accuracy train:  0.655\n",
      "Accuracy test:  0.5405405405405406\n",
      "Training...\n",
      "Testing...\n",
      "Accuracy train deterministic 0.6525097671511174\n",
      "Accuracy test deterministic 0.6491228070175439\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Biased sample:  False\n",
      "alpha:  0.92\n",
      "Drop Easier instances: False\n",
      "Modfied prior False\n",
      "VVV_v3_RRc VVV_v3_ELL\n",
      "Running Define TrainSet\n",
      "(10000, 62)\n",
      "Test size:  1999\n",
      "Shape training:  (8000, 60)\n",
      "Shape testing:  (2000, 60)\n",
      "Running experiments\n",
      "(8000, 60)\n",
      "(2000, 60)\n",
      "6\n",
      "Index(['Class', 'PC0', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8',\n",
      "       'PC9', 'PC10', 'PC11'],\n",
      "      dtype='object')\n",
      "------- Metropolis--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sequential sampling (2 chains in 1 job)\n",
      "CompoundStep\n",
      ">Metropolis: [PC11]\n",
      ">Metropolis: [PC10]\n",
      ">Metropolis: [PC9]\n",
      ">Metropolis: [PC8]\n",
      ">Metropolis: [PC7]\n",
      ">Metropolis: [PC6]\n",
      ">Metropolis: [PC5]\n",
      ">Metropolis: [PC4]\n",
      ">Metropolis: [PC3]\n",
      ">Metropolis: [PC2]\n",
      ">Metropolis: [PC1]\n",
      ">Metropolis: [PC0]\n",
      ">Metropolis: [Intercept]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 20500/20500 [05:16<00:00, 64.81it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 20500/20500 [05:16<00:00, 64.72it/s]\n",
      "The gelman-rubin statistic is larger than 1.05 for some parameters. This indicates slight problems during sampling.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "20000\n",
      "10000\n",
      "20000\n",
      "20000\n",
      "The Bridge Sampling Estimatation of Logml is -541.44524\n",
      "return the last model and trace\n",
      "Accuracy train:  0.6525\n",
      "Accuracy test:  0.6216216216216216\n",
      "Training...\n",
      "Testing...\n",
      "Accuracy train deterministic 0.6525097671511174\n",
      "Accuracy test deterministic 0.6491228070175439\n",
      "-----------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for k in [2, 4, 6]:\n",
    "    for a in alpha:\n",
    "        try:\n",
    "            print('Biased sample: ', biased)\n",
    "            print('alpha: ', a)\n",
    "            print('Drop Easier instances:', DropEasy)\n",
    "            print('Modfied prior', prior)\n",
    "            print(label1, label2)\n",
    "            results_summary, model_ogle, trace, dataTrain, dataTest = exp.runExperiments(Data,  class_1= label1, class_2=label2, components= [k],\n",
    "                                                                                                             method=[7], size=[0.8], ml= True, \n",
    "                                                                                                             fit_iterations= 20000, name_class_col_= Class_col, \n",
    "                                                                                                             id_col_=ID, biasedSplit = biased, \n",
    "                                                                                                             ModifiedPrior = prior, DropEasy_ =  DropEasy, alpha_ = a, \n",
    "                                                                                                            PCA_ = PCA, kernel = True, poli = 2)\n",
    "            label = dataTrain['label']\n",
    "            labelTest = dataTest['label']\n",
    "            del dataTrain['label']\n",
    "            del dataTest['label']\n",
    "\n",
    "            r = ut.get_z(dataTrain, trace = trace, burn_in = 500)\n",
    "            predictions_1_Train = ut.logistic_function_(r).mean(axis=1)>0.5\n",
    "            acc1 = accuracy_score(label, predictions_1_Train, normalize=True)\n",
    "            print('Accuracy train: ', acc1)\n",
    "\n",
    "            r = ut.get_z(dataTest, trace = trace, burn_in = 500)\n",
    "            predictions_1_Test = ut.logistic_function_(r).mean(axis=1)>0.5\n",
    "            acc2 = accuracy_score(labelTest, predictions_1_Test, normalize=True)\n",
    "            print('Accuracy test: ', acc2)\n",
    "\n",
    "\n",
    "\n",
    "            n_split_train = 10 #int(dataTrain.shape[0]/obs_fold)\n",
    "            n_split_test = 10 #int(dataTest.shape[0]/ obs_fold)\n",
    "            clf1 = linearModel.LogisticRegression(C=1.0)\n",
    "            acc_kfold, acc_kfold_Test = ut.KFold(dataTrain, label, dataTest, labelTest, n_split_test, n_split_train, clf1)\n",
    "\n",
    "            print('Accuracy train deterministic', np.mean(acc_kfold))\n",
    "            print('Accuracy test deterministic', np.mean(acc_kfold_Test))\n",
    "            summaryAcurracy.append([k, a, label1, label2, label.shape[0],labelTest.shape[0], results_summary[4][0], acc1, acc2, np.mean(acc_kfold), np.mean(acc_kfold_Test), biased, DropEasy, prior])\n",
    "            print('-----------------------------------------------------------------------------------------------')\n",
    "            results.append([results_summary, accuracy_score(label, predictions_1_Train, normalize=True), accuracy_score(labelTest, predictions_1_Test, normalize=True), np.mean(acc_kfold), np.mean(acc_kfold_Test), acc_kfold, acc_kfold_Test])\n",
    "        except: \n",
    "            print('Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k in [2, 4, 6]:\n",
    "    for a in alpha:\n",
    "        try:\n",
    "            print('Biased sample: ', biased)\n",
    "            print('alpha: ', a)\n",
    "            print('Drop Easier instances:', DropEasy)\n",
    "            print('Modfied prior', prior)\n",
    "            print(label1, label2)\n",
    "            results_summary, model_ogle, trace, dataTrain, dataTest = exp.runExperiments(Data,  class_1= label1, class_2=label2, components= [k],\n",
    "                                                                                                             method=[7], size=[0.8], ml= True, \n",
    "                                                                                                             fit_iterations= 20000, name_class_col_= Class_col, \n",
    "                                                                                                             id_col_=ID, biasedSplit = biased, \n",
    "                                                                                                             ModifiedPrior = prior, DropEasy_ =  DropEasy, alpha_ = a, \n",
    "                                                                                                            PCA_ = PCA, kernel = True, poli = )\n",
    "            label = dataTrain['label']\n",
    "            labelTest = dataTest['label']\n",
    "            del dataTrain['label']\n",
    "            del dataTest['label']\n",
    "\n",
    "            r = ut.get_z(dataTrain, trace = trace, burn_in = 500)\n",
    "            predictions_1_Train = ut.logistic_function_(r).mean(axis=1)>0.5\n",
    "            acc1 = accuracy_score(label, predictions_1_Train, normalize=True)\n",
    "            print('Accuracy train: ', acc1)\n",
    "\n",
    "            r = ut.get_z(dataTest, trace = trace, burn_in = 500)\n",
    "            predictions_1_Test = ut.logistic_function_(r).mean(axis=1)>0.5\n",
    "            acc2 = accuracy_score(labelTest, predictions_1_Test, normalize=True)\n",
    "            print('Accuracy test: ', acc2)\n",
    "\n",
    "\n",
    "\n",
    "            n_split_train = 10 #int(dataTrain.shape[0]/obs_fold)\n",
    "            n_split_test = 10 #int(dataTest.shape[0]/ obs_fold)\n",
    "            clf1 = linearModel.LogisticRegression(C=1.0)\n",
    "            acc_kfold, acc_kfold_Test = ut.KFold(dataTrain, label, dataTest, labelTest, n_split_test, n_split_train, clf1)\n",
    "\n",
    "            print('Accuracy train deterministic', np.mean(acc_kfold))\n",
    "            print('Accuracy test deterministic', np.mean(acc_kfold_Test))\n",
    "            summaryAcurracy.append([k, a, label1, label2, label.shape[0],labelTest.shape[0], results_summary[4][0], acc1, acc2, np.mean(acc_kfold), np.mean(acc_kfold_Test), biased, DropEasy, prior])\n",
    "            print('-----------------------------------------------------------------------------------------------')\n",
    "            results.append([results_summary, accuracy_score(label, predictions_1_Train, normalize=True), accuracy_score(labelTest, predictions_1_Test, normalize=True), np.mean(acc_kfold), np.mean(acc_kfold_Test), acc_kfold, acc_kfold_Test])\n",
    "        except: \n",
    "            print('Error')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
