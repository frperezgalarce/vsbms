{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import  sklearn.linear_model as linearModel\n",
    "from sklearn import preprocessing\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "#import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from warnings import filterwarnings\n",
    "import timeit\n",
    "import pymc3 as pm\n",
    "import sys\n",
    "import json\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0,'../src')\n",
    "import bridgeSampling as bs # it contains a method to estimate the marginal likelihood according to the Bridge Sampling approach\n",
    "import utilFunctions as ut          # it has different methods to handle and plot data\n",
    "import BayesianModels as bm # it has methods to build and train bayesian model (Logistic Regression and Neural Nets)\n",
    "import experiments as exp\n",
    "import samplebiasselection as sbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 1\n",
    "fileTrain = '/home/francisco/Escritorio/code/vsbms/data/BIASEDFATS/Train_rrlyr-'+str(number)+'.csv'\n",
    "fileTest = '/home/francisco/Escritorio/code/vsbms/data/BIASEDFATS/Test_rrlyr-'+str(number)+'.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Ridge Logistic Regresion (Polynomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel 1\n",
      "components 2\n",
      "71\n",
      "training fold 1\n",
      "Accuracy train:  0.87\n",
      "training fold 2\n",
      "Accuracy train:  0.9\n",
      "training fold 3\n",
      "Accuracy train:  0.95\n",
      "training fold 4\n",
      "Accuracy train:  0.93\n",
      "training fold 5\n",
      "Accuracy train:  0.86\n",
      "training fold 6\n",
      "Accuracy train:  0.95\n",
      "training fold 7\n",
      "Accuracy train:  0.89\n",
      "training fold 8\n",
      "Accuracy train:  0.95\n",
      "training fold 9\n",
      "Accuracy train:  0.89\n",
      "training fold 10\n",
      "Accuracy train:  0.89\n",
      "----------------------------------------------------------\n",
      "Summary Training\n",
      "Mean Accuracy train:  0.908\n",
      "Mean f1 Train:  0.9081880062508946\n",
      "(28625,)\n",
      "(28625,)\n",
      "----------------------------------------------------------\n",
      "Summary Testing\n",
      " Accuracy test:  0.6015021834061135\n",
      " f1 test:  0.5970254707316212\n",
      "----------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary +: 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-143cef82cb9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomponents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0maccTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1Train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1Test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'-BasicCV0107C'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: bad operand type for unary +: 'str'"
     ]
    }
   ],
   "source": [
    "Cvalue = 1\n",
    "plot = False\n",
    "basicLR_stats_acc = []\n",
    "basicLR_stats_f1 = []\n",
    "res = []\n",
    "for k in [1, 2, 3]:\n",
    "    print('kernel '+str(k))\n",
    "    for components in [2, 4, 6, 8, 10, 12, 14]:\n",
    "        for size in[1000, 2000, 4000]:\n",
    "            print('components '+str(components))\n",
    "            dataTrain = pd.read_csv(fileTrain)\n",
    "            dataTest = pd.read_csv(fileTest)\n",
    "            print(len(dataTrain.columns)) \n",
    "            try:\n",
    "                dataTrain = dataTrain.loc[:, ~dataTrain.columns.str.contains('^Unnamed')]\n",
    "                dataTrain =  dataTrain.drop(['Pred', 'Pred2', 'h', 'e', 'u','ID'], axis = 1)\n",
    "                dataTrain = dataTrain.loc[:, (dataTrain != dataTrain.iloc[0]).any()]\n",
    "                dataTest = dataTest[list(dataTrain.columns)]\n",
    "\n",
    "            except:\n",
    "                print('---')\n",
    "            dataTrain = ut.downSampling(dataTrain)\n",
    "            try:\n",
    "                dataTrain = dataTrain.sample(size, random_state = 0)\n",
    "            except:\n",
    "                print('sample bigger that population')\n",
    "            yTrain = 1*(dataTrain['label'] == 'ClassA')\n",
    "            yTestHO = 1*(dataTest['label'] == 'ClassA')\n",
    "            del dataTrain['label']\n",
    "            del dataTest['label']\n",
    "\n",
    "            names = dataTrain.columns\n",
    "            scaler = preprocessing.StandardScaler()\n",
    "            dataTrain = scaler.fit_transform(dataTrain)\n",
    "            dataTrain = pd.DataFrame(dataTrain, columns=names)\n",
    "\n",
    "            dataTest = scaler.fit_transform(dataTest)\n",
    "            dataTest = pd.DataFrame(dataTest, columns=names)\n",
    "\n",
    "\n",
    "            pca = PCA(n_components=components)\n",
    "            pca.fit(dataTrain)\n",
    "            dataTrain = pca.transform(dataTrain)\n",
    "            dataTrain = pd.DataFrame(dataTrain)\n",
    "            dataTrain = ut.Polinomial(dataTrain,k)\n",
    "\n",
    "\n",
    "            pca.fit(dataTest)\n",
    "            dataTest = pca.transform(dataTest)\n",
    "            dataTest = pd.DataFrame(dataTest)\n",
    "            dataTest = ut.Polinomial(dataTest,k)\n",
    "            #size = dataTrain.shape[0]\n",
    "\n",
    "            start_1 = timeit.default_timer()\n",
    "            skf = StratifiedKFold(n_splits=int(10))\n",
    "            skf.get_n_splits(dataTrain, yTrain)\n",
    "            acc_kfold_Train = []\n",
    "            f1_kfold_Train = []\n",
    "            i = 0\n",
    "\n",
    "            for train_index, test_index in skf.split(dataTrain, yTrain):\n",
    "                        i = i+1\n",
    "                        print('training fold ' + str(i))\n",
    "                        X_train, X_test = dataTrain.iloc[train_index,:], dataTrain.iloc[test_index,:]\n",
    "                        y_train, y_test = yTrain.iloc[train_index], yTrain.iloc[test_index]\n",
    "\n",
    "                        basicLR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial',\n",
    "                                                     C=Cvalue).fit(X_train, y_train)\n",
    "                        predictions_1_Train = basicLR.predict(X_test)\n",
    "\n",
    "                        accTrain = accuracy_score(y_test, predictions_1_Train, normalize=True)\n",
    "                        f1Train = f1_score(y_test, predictions_1_Train, pos_label = 1)\n",
    "\n",
    "                        if plot:\n",
    "                            cm = confusion_matrix(y_test, predictions_1_Train)\n",
    "                            ut.plot_confusion_matrix(cm, ['all', 'rrlyr'], type = 'train')\n",
    "                        print('Accuracy train: ', accTrain)\n",
    "                        #print('Accuracy f1 Train: ', f1Train)\n",
    "                        basicLR_stats_acc.append(accTrain)\n",
    "                        basicLR_stats_f1.append(f1Train)\n",
    "            accTrain = np.mean(basicLR_stats_acc)\n",
    "            f1Train =np.mean(basicLR_stats_f1)\n",
    "            print('----------------------------------------------------------')\n",
    "            print('Summary Training')\n",
    "            print('Mean Accuracy train: ', accTrain)\n",
    "            print('Mean f1 Train: ', f1Train)\n",
    "            stop_1 = timeit.default_timer()\n",
    "            time_CV = stop_1 - start_1\n",
    "            basicLR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial', C=Cvalue).fit(dataTrain, yTrain)\n",
    "            predictions_1_Test = basicLR.predict(dataTest)\n",
    "            print(predictions_1_Test.shape)\n",
    "            print(yTestHO.shape)\n",
    "            print('----------------------------------------------------------')\n",
    "            print('Summary Testing')\n",
    "            accTest = accuracy_score(yTestHO, predictions_1_Test, normalize=True)\n",
    "            f1Test = f1_score(yTestHO, predictions_1_Test,pos_label = 1)\n",
    "            if plot: \n",
    "                cm = confusion_matrix(yTestHO, predictions_1_Test)\n",
    "                ut.plot_confusion_matrix(cm, ['all', 'rrlyr'], type = 'train')\n",
    "\n",
    "            print(' Accuracy test: ', accTest)\n",
    "            print(' f1 test: ', f1Test)\n",
    "            print('----------------------------------------------------------')\n",
    "\n",
    "            res.append([k, components, size,  accTrain, accTest, f1Train, f1Test])\n",
    "            pd.DataFrame(res).to_csv(+str(number)+'-BasicCV0107C'+str(Cvalue)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel 1\n",
      "components 2\n",
      "71\n",
      "training fold 1\n",
      "Accuracy train:  0.87\n",
      "training fold 2\n",
      "Accuracy train:  0.9\n",
      "training fold 3\n",
      "Accuracy train:  0.95\n",
      "training fold 4\n",
      "Accuracy train:  0.93\n",
      "training fold 5\n",
      "Accuracy train:  0.86\n",
      "training fold 6\n",
      "Accuracy train:  0.95\n",
      "training fold 7\n",
      "Accuracy train:  0.89\n",
      "training fold 8\n",
      "Accuracy train:  0.95\n",
      "training fold 9\n",
      "Accuracy train:  0.88\n",
      "training fold 10\n",
      "Accuracy train:  0.89\n",
      "----------------------------------------------------------\n",
      "Summary Training\n",
      "Mean Accuracy train:  0.907\n",
      "Mean f1 Train:  0.9073143894774525\n",
      "(28625,)\n",
      "(28625,)\n",
      "----------------------------------------------------------\n",
      "Summary Testing\n",
      " Accuracy test:  0.6017467248908297\n",
      " f1 test:  0.5972016111935552\n",
      "----------------------------------------------------------\n",
      "components 2\n",
      "71\n",
      "training fold 1\n",
      "Accuracy train:  0.9\n",
      "training fold 2\n",
      "Accuracy train:  0.94\n",
      "training fold 3\n",
      "Accuracy train:  0.905\n",
      "training fold 4\n",
      "Accuracy train:  0.925\n",
      "training fold 5\n",
      "Accuracy train:  0.88\n",
      "training fold 6\n",
      "Accuracy train:  0.905\n",
      "training fold 7\n",
      "Accuracy train:  0.92\n",
      "training fold 8\n",
      "Accuracy train:  0.92\n",
      "training fold 9\n",
      "Accuracy train:  0.94\n",
      "training fold 10\n",
      "Accuracy train:  0.965\n",
      "----------------------------------------------------------\n",
      "Summary Training\n",
      "Mean Accuracy train:  0.9135000000000002\n",
      "Mean f1 Train:  0.9146211543977693\n",
      "(28625,)\n",
      "(28625,)\n",
      "----------------------------------------------------------\n",
      "Summary Testing\n",
      " Accuracy test:  0.6057292576419214\n",
      " f1 test:  0.6051360996431321\n",
      "----------------------------------------------------------\n",
      "components 2\n",
      "71\n",
      "training fold 1\n",
      "Accuracy train:  0.925\n",
      "training fold 2\n",
      "Accuracy train:  0.92\n",
      "training fold 3\n",
      "Accuracy train:  0.905\n",
      "training fold 4\n",
      "Accuracy train:  0.9225\n",
      "training fold 5\n",
      "Accuracy train:  0.9525\n",
      "training fold 6\n",
      "Accuracy train:  0.9175\n",
      "training fold 7\n",
      "Accuracy train:  0.9225\n",
      "training fold 8\n",
      "Accuracy train:  0.92\n",
      "training fold 9\n",
      "Accuracy train:  0.9225\n",
      "training fold 10\n",
      "Accuracy train:  0.9025\n",
      "----------------------------------------------------------\n",
      "Summary Training\n",
      "Mean Accuracy train:  0.916\n",
      "Mean f1 Train:  0.9175741732447593\n",
      "(28625,)\n",
      "(28625,)\n",
      "----------------------------------------------------------\n",
      "Summary Testing\n",
      " Accuracy test:  0.6026899563318777\n",
      " f1 test:  0.6048709307577389\n",
      "----------------------------------------------------------\n",
      "components 4\n",
      "71\n",
      "training fold 1\n",
      "Accuracy train:  1.0\n",
      "training fold 2\n",
      "Accuracy train:  0.96\n",
      "training fold 3\n",
      "Accuracy train:  0.98\n",
      "training fold 4\n",
      "Accuracy train:  0.97\n",
      "training fold 5\n",
      "Accuracy train:  0.96\n",
      "training fold 6\n",
      "Accuracy train:  0.97\n",
      "training fold 7\n",
      "Accuracy train:  0.97\n",
      "training fold 8\n",
      "Accuracy train:  0.99\n",
      "training fold 9\n",
      "Accuracy train:  0.94\n",
      "training fold 10\n",
      "Accuracy train:  0.94\n",
      "----------------------------------------------------------\n",
      "Summary Training\n",
      "Mean Accuracy train:  0.9289999999999999\n",
      "Mean f1 Train:  0.9301296871294487\n",
      "(28625,)\n",
      "(28625,)\n",
      "----------------------------------------------------------\n",
      "Summary Testing\n",
      " Accuracy test:  0.6224628820960698\n",
      " f1 test:  0.6146824972367811\n",
      "----------------------------------------------------------\n",
      "components 4\n",
      "71\n",
      "training fold 1\n",
      "Accuracy train:  0.98\n",
      "training fold 2\n",
      "Accuracy train:  0.975\n",
      "training fold 3\n",
      "Accuracy train:  0.965\n",
      "training fold 4\n",
      "Accuracy train:  0.98\n",
      "training fold 5\n",
      "Accuracy train:  0.95\n",
      "training fold 6\n",
      "Accuracy train:  0.965\n",
      "training fold 7\n",
      "Accuracy train:  0.975\n",
      "training fold 8\n",
      "Accuracy train:  0.98\n",
      "training fold 9\n",
      "Accuracy train:  0.97\n",
      "training fold 10\n",
      "Accuracy train:  0.98\n",
      "----------------------------------------------------------\n",
      "Summary Training\n",
      "Mean Accuracy train:  0.9375999999999999\n",
      "Mean f1 Train:  0.9385701844194769\n",
      "(28625,)\n",
      "(28625,)\n",
      "----------------------------------------------------------\n",
      "Summary Testing\n",
      " Accuracy test:  0.6234410480349345\n",
      " f1 test:  0.6185099982304018\n",
      "----------------------------------------------------------\n",
      "components 4\n",
      "71\n",
      "training fold 1\n",
      "Accuracy train:  0.975\n",
      "training fold 2\n",
      "Accuracy train:  0.965\n",
      "training fold 3\n",
      "Accuracy train:  0.9625\n",
      "training fold 4\n",
      "Accuracy train:  0.9725\n",
      "training fold 5\n",
      "Accuracy train:  0.98\n",
      "training fold 6\n",
      "Accuracy train:  0.965\n",
      "training fold 7\n",
      "Accuracy train:  0.9725\n",
      "training fold 8\n",
      "Accuracy train:  0.97\n",
      "training fold 9\n",
      "Accuracy train:  0.96\n",
      "training fold 10\n",
      "Accuracy train:  0.97\n",
      "----------------------------------------------------------\n",
      "Summary Training\n",
      "Mean Accuracy train:  0.942875\n",
      "Mean f1 Train:  0.943820290599626\n",
      "(28625,)\n",
      "(28625,)\n",
      "----------------------------------------------------------\n",
      "Summary Testing\n",
      " Accuracy test:  0.6345152838427948\n",
      " f1 test:  0.6342469584673474\n",
      "----------------------------------------------------------\n",
      "components 6\n",
      "71\n",
      "training fold 1\n",
      "Accuracy train:  0.98\n",
      "training fold 2\n",
      "Accuracy train:  0.96\n",
      "training fold 3\n",
      "Accuracy train:  0.98\n",
      "training fold 4\n",
      "Accuracy train:  0.97\n",
      "training fold 5\n",
      "Accuracy train:  0.95\n",
      "training fold 6\n",
      "Accuracy train:  0.97\n",
      "training fold 7\n",
      "Accuracy train:  0.97\n",
      "training fold 8\n",
      "Accuracy train:  0.99\n",
      "training fold 9\n",
      "Accuracy train:  0.95\n",
      "training fold 10\n",
      "Accuracy train:  0.96\n",
      "----------------------------------------------------------\n",
      "Summary Training\n",
      "Mean Accuracy train:  0.9464642857142856\n",
      "Mean f1 Train:  0.9472600510628687\n",
      "(28625,)\n",
      "(28625,)\n",
      "----------------------------------------------------------\n",
      "Summary Testing\n",
      " Accuracy test:  0.612646288209607\n",
      " f1 test:  0.5896980461811723\n",
      "----------------------------------------------------------\n",
      "components 6\n",
      "71\n",
      "training fold 1\n",
      "Accuracy train:  0.98\n",
      "training fold 2\n",
      "Accuracy train:  0.98\n",
      "training fold 3\n",
      "Accuracy train:  0.955\n",
      "training fold 4\n",
      "Accuracy train:  0.98\n",
      "training fold 5\n",
      "Accuracy train:  0.955\n",
      "training fold 6\n",
      "Accuracy train:  0.96\n",
      "training fold 7\n",
      "Accuracy train:  0.97\n",
      "training fold 8\n",
      "Accuracy train:  0.975\n",
      "training fold 9\n",
      "Accuracy train:  0.98\n",
      "training fold 10\n",
      "Accuracy train:  0.985\n",
      "----------------------------------------------------------\n",
      "Summary Training\n",
      "Mean Accuracy train:  0.94965625\n",
      "Mean f1 Train:  0.9503988556130594\n",
      "(28625,)\n",
      "(28625,)\n",
      "----------------------------------------------------------\n",
      "Summary Testing\n",
      " Accuracy test:  0.6201921397379913\n",
      " f1 test:  0.607877082882493\n",
      "----------------------------------------------------------\n",
      "components 6\n",
      "71\n",
      "training fold 1\n",
      "Accuracy train:  0.985\n",
      "training fold 2\n",
      "Accuracy train:  0.9825\n",
      "training fold 3\n",
      "Accuracy train:  0.965\n",
      "training fold 4\n",
      "Accuracy train:  0.98\n",
      "training fold 5\n",
      "Accuracy train:  0.9825\n",
      "training fold 6\n",
      "Accuracy train:  0.975\n",
      "training fold 7\n",
      "Accuracy train:  0.9875\n",
      "training fold 8\n",
      "Accuracy train:  0.97\n",
      "training fold 9\n",
      "Accuracy train:  0.9725\n",
      "training fold 10\n",
      "Accuracy train:  0.9675\n",
      "----------------------------------------------------------\n",
      "Summary Training\n",
      "Mean Accuracy train:  0.9526666666666668\n",
      "Mean f1 Train:  0.9533980525771071\n",
      "(28625,)\n",
      "(28625,)\n",
      "----------------------------------------------------------\n",
      "Summary Testing\n",
      " Accuracy test:  0.6278078602620087\n",
      " f1 test:  0.6224663359319632\n",
      "----------------------------------------------------------\n",
      "components 8\n",
      "71\n",
      "training fold 1\n",
      "Accuracy train:  0.99\n",
      "training fold 2\n",
      "Accuracy train:  0.97\n",
      "training fold 3\n",
      "Accuracy train:  0.98\n",
      "training fold 4\n",
      "Accuracy train:  0.98\n",
      "training fold 5\n",
      "Accuracy train:  0.95\n",
      "training fold 6\n",
      "Accuracy train:  0.97\n",
      "training fold 7\n",
      "Accuracy train:  0.99\n",
      "training fold 8\n",
      "Accuracy train:  0.96\n",
      "training fold 9\n",
      "Accuracy train:  0.97\n",
      "training fold 10\n",
      "Accuracy train:  0.98\n",
      "----------------------------------------------------------\n",
      "Summary Training\n",
      "Mean Accuracy train:  0.9547999999999999\n",
      "Mean f1 Train:  0.9554834566613171\n",
      "(28625,)\n",
      "(28625,)\n",
      "----------------------------------------------------------\n",
      "Summary Testing\n",
      " Accuracy test:  0.6040873362445415\n",
      " f1 test:  0.5633260124070436\n",
      "----------------------------------------------------------\n",
      "components 8\n",
      "71\n",
      "training fold 1\n",
      "Accuracy train:  0.99\n",
      "training fold 2\n",
      "Accuracy train:  0.98\n",
      "training fold 3\n",
      "Accuracy train:  0.965\n",
      "training fold 4\n",
      "Accuracy train:  0.975\n",
      "training fold 5\n",
      "Accuracy train:  0.965\n",
      "training fold 6\n",
      "Accuracy train:  0.965\n",
      "training fold 7\n",
      "Accuracy train:  0.975\n",
      "training fold 8\n",
      "Accuracy train:  0.975\n",
      "training fold 9\n",
      "Accuracy train:  0.98\n",
      "training fold 10\n",
      "Accuracy train:  0.985\n",
      "----------------------------------------------------------\n",
      "Summary Training\n",
      "Mean Accuracy train:  0.9566818181818182\n",
      "Mean f1 Train:  0.9573439317989768\n",
      "(28625,)\n",
      "(28625,)\n",
      "----------------------------------------------------------\n",
      "Summary Testing\n",
      " Accuracy test:  0.6089082969432315\n",
      " f1 test:  0.5767965826182285\n",
      "----------------------------------------------------------\n",
      "components 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "training fold 1\n",
      "Accuracy train:  0.9875\n",
      "training fold 2\n",
      "Accuracy train:  0.98\n",
      "training fold 3\n",
      "Accuracy train:  0.9675\n",
      "training fold 4\n",
      "Accuracy train:  0.98\n",
      "training fold 5\n",
      "Accuracy train:  0.98\n",
      "training fold 6\n",
      "Accuracy train:  0.975\n",
      "training fold 7\n",
      "Accuracy train:  0.985\n",
      "training fold 8\n",
      "Accuracy train:  0.97\n",
      "training fold 9\n",
      "Accuracy train:  0.9725\n",
      "training fold 10\n",
      "Accuracy train:  0.9675\n",
      "----------------------------------------------------------\n",
      "Summary Training\n",
      "Mean Accuracy train:  0.9583333333333334\n",
      "Mean f1 Train:  0.95899301542213\n",
      "(28625,)\n",
      "(28625,)\n",
      "----------------------------------------------------------\n",
      "Summary Testing\n",
      " Accuracy test:  0.6284017467248908\n",
      " f1 test:  0.6227345273984749\n",
      "----------------------------------------------------------\n",
      "components 10\n",
      "71\n",
      "training fold 1\n",
      "Accuracy train:  0.99\n",
      "training fold 2\n",
      "Accuracy train:  0.98\n",
      "training fold 3\n",
      "Accuracy train:  0.99\n",
      "training fold 4\n",
      "Accuracy train:  0.97\n",
      "training fold 5\n",
      "Accuracy train:  0.97\n",
      "training fold 6\n",
      "Accuracy train:  0.98\n",
      "training fold 7\n",
      "Accuracy train:  0.99\n",
      "training fold 8\n",
      "Accuracy train:  0.97\n",
      "training fold 9\n",
      "Accuracy train:  0.97\n",
      "training fold 10\n",
      "Accuracy train:  0.97\n",
      "----------------------------------------------------------\n",
      "Summary Training\n",
      "Mean Accuracy train:  0.9598461538461539\n",
      "Mean f1 Train:  0.9604621520725611\n",
      "(28625,)\n",
      "(28625,)\n",
      "----------------------------------------------------------\n",
      "Summary Testing\n",
      " Accuracy test:  0.5993711790393013\n",
      " f1 test:  0.5715139739949185\n",
      "----------------------------------------------------------\n",
      "components 10\n",
      "71\n",
      "training fold 1\n",
      "Accuracy train:  0.975\n",
      "training fold 2\n",
      "Accuracy train:  0.985\n",
      "training fold 3\n",
      "Accuracy train:  0.98\n",
      "training fold 4\n",
      "Accuracy train:  0.98\n",
      "training fold 5\n",
      "Accuracy train:  0.965\n",
      "training fold 6\n",
      "Accuracy train:  0.97\n",
      "training fold 7\n",
      "Accuracy train:  0.98\n",
      "training fold 8\n",
      "Accuracy train:  0.985\n",
      "training fold 9\n",
      "Accuracy train:  0.98\n",
      "training fold 10\n",
      "Accuracy train:  0.98\n",
      "----------------------------------------------------------\n",
      "Summary Training\n",
      "Mean Accuracy train:  0.9611428571428572\n",
      "Mean f1 Train:  0.9617460040866581\n",
      "(28625,)\n",
      "(28625,)\n",
      "----------------------------------------------------------\n",
      "Summary Testing\n",
      " Accuracy test:  0.6024454148471615\n",
      " f1 test:  0.5812481601413011\n",
      "----------------------------------------------------------\n",
      "components 10\n",
      "71\n",
      "training fold 1\n",
      "Accuracy train:  0.98\n",
      "training fold 2\n",
      "Accuracy train:  0.9775\n",
      "training fold 3\n",
      "Accuracy train:  0.965\n",
      "training fold 4\n",
      "Accuracy train:  0.985\n",
      "training fold 5\n",
      "Accuracy train:  0.9825\n",
      "training fold 6\n",
      "Accuracy train:  0.985\n",
      "training fold 7\n",
      "Accuracy train:  0.9825\n",
      "training fold 8\n",
      "Accuracy train:  0.98\n",
      "training fold 9\n",
      "Accuracy train:  0.9775\n",
      "training fold 10\n",
      "Accuracy train:  0.97\n",
      "----------------------------------------------------------\n",
      "Summary Training\n",
      "Mean Accuracy train:  0.9623000000000002\n",
      "Mean f1 Train:  0.9629033004886826\n",
      "(28625,)\n",
      "(28625,)\n",
      "----------------------------------------------------------\n",
      "Summary Testing\n",
      " Accuracy test:  0.6474759825327511\n",
      " f1 test:  0.6393624245023409\n",
      "----------------------------------------------------------\n",
      "components 12\n",
      "71\n",
      "training fold 1\n",
      "Accuracy train:  0.99\n",
      "training fold 2\n",
      "Accuracy train:  0.98\n",
      "training fold 3\n",
      "Accuracy train:  1.0\n",
      "training fold 4\n",
      "Accuracy train:  0.98\n",
      "training fold 5\n",
      "Accuracy train:  0.97\n",
      "training fold 6\n",
      "Accuracy train:  0.99\n",
      "training fold 7\n",
      "Accuracy train:  0.99\n",
      "training fold 8\n",
      "Accuracy train:  0.98\n",
      "training fold 9\n",
      "Accuracy train:  0.97\n",
      "training fold 10\n",
      "Accuracy train:  0.97\n",
      "----------------------------------------------------------\n",
      "Summary Training\n",
      "Mean Accuracy train:  0.9635312500000002\n",
      "Mean f1 Train:  0.9641004187544967\n",
      "(28625,)\n",
      "(28625,)\n",
      "----------------------------------------------------------\n",
      "Summary Testing\n",
      " Accuracy test:  0.5959126637554585\n",
      " f1 test:  0.5702077063129343\n",
      "----------------------------------------------------------\n",
      "components 12\n",
      "71\n",
      "training fold 1\n",
      "Accuracy train:  0.99\n",
      "training fold 2\n",
      "Accuracy train:  0.995\n",
      "training fold 3\n",
      "Accuracy train:  0.98\n",
      "training fold 4\n",
      "Accuracy train:  0.985\n",
      "training fold 5\n",
      "Accuracy train:  0.98\n",
      "training fold 6\n",
      "Accuracy train:  0.965\n",
      "training fold 7\n",
      "Accuracy train:  0.98\n",
      "training fold 8\n",
      "Accuracy train:  0.995\n",
      "training fold 9\n",
      "Accuracy train:  0.98\n",
      "training fold 10\n",
      "Accuracy train:  0.99\n",
      "----------------------------------------------------------\n",
      "Summary Training\n",
      "Mean Accuracy train:  0.964735294117647\n",
      "Mean f1 Train:  0.9652879420295803\n",
      "(28625,)\n",
      "(28625,)\n",
      "----------------------------------------------------------\n",
      "Summary Testing\n",
      " Accuracy test:  0.6000349344978166\n",
      " f1 test:  0.5850759250534556\n",
      "----------------------------------------------------------\n",
      "components 12\n",
      "71\n",
      "training fold 1\n",
      "Accuracy train:  0.985\n",
      "training fold 2\n",
      "Accuracy train:  0.985\n",
      "training fold 3\n",
      "Accuracy train:  0.975\n",
      "training fold 4\n",
      "Accuracy train:  0.99\n",
      "training fold 5\n",
      "Accuracy train:  0.985\n",
      "training fold 6\n",
      "Accuracy train:  0.99\n",
      "training fold 7\n",
      "Accuracy train:  0.9925\n",
      "training fold 8\n",
      "Accuracy train:  0.975\n",
      "training fold 9\n",
      "Accuracy train:  0.975\n",
      "training fold 10\n",
      "Accuracy train:  0.98\n",
      "----------------------------------------------------------\n",
      "Summary Training\n",
      "Mean Accuracy train:  0.9657638888888891\n",
      "Mean f1 Train:  0.9663085294156537\n",
      "(28625,)\n",
      "(28625,)\n",
      "----------------------------------------------------------\n",
      "Summary Testing\n",
      " Accuracy test:  0.6510742358078603\n",
      " f1 test:  0.6536274101817173\n",
      "----------------------------------------------------------\n",
      "kernel 2\n",
      "components 2\n",
      "71\n",
      "training fold 1\n",
      "Accuracy train:  0.87\n",
      "training fold 2\n",
      "Accuracy train:  0.91\n",
      "training fold 3\n",
      "Accuracy train:  0.99\n",
      "training fold 4\n",
      "Accuracy train:  0.95\n",
      "training fold 5\n",
      "Accuracy train:  0.94\n",
      "training fold 6\n",
      "Accuracy train:  0.96\n",
      "training fold 7\n",
      "Accuracy train:  0.96\n",
      "training fold 8\n",
      "Accuracy train:  0.95\n",
      "training fold 9\n",
      "Accuracy train:  0.94\n",
      "training fold 10\n",
      "Accuracy train:  0.93\n",
      "----------------------------------------------------------\n",
      "Summary Training\n",
      "Mean Accuracy train:  0.9644078947368422\n",
      "Mean f1 Train:  0.9650285493428308\n",
      "(28625,)\n",
      "(28625,)\n",
      "----------------------------------------------------------\n",
      "Summary Testing\n",
      " Accuracy test:  0.6185152838427947\n",
      " f1 test:  0.5780525502318392\n",
      "----------------------------------------------------------\n",
      "components 2\n",
      "71\n",
      "training fold 1\n",
      "Accuracy train:  0.9\n",
      "training fold 2\n",
      "Accuracy train:  0.975\n",
      "training fold 3\n",
      "Accuracy train:  0.945\n",
      "training fold 4\n",
      "Accuracy train:  0.955\n",
      "training fold 5\n",
      "Accuracy train:  0.93\n",
      "training fold 6\n",
      "Accuracy train:  0.935\n",
      "training fold 7\n",
      "Accuracy train:  0.955\n",
      "training fold 8\n",
      "Accuracy train:  0.94\n",
      "training fold 9\n",
      "Accuracy train:  0.96\n",
      "training fold 10\n",
      "Accuracy train:  0.97\n",
      "----------------------------------------------------------\n",
      "Summary Training\n",
      "Mean Accuracy train:  0.9635124999999999\n",
      "Mean f1 Train:  0.9642166432204278\n",
      "(28625,)\n",
      "(28625,)\n",
      "----------------------------------------------------------\n",
      "Summary Testing\n",
      " Accuracy test:  0.623056768558952\n",
      " f1 test:  0.5915663562722386\n",
      "----------------------------------------------------------\n",
      "components 2\n",
      "71\n",
      "training fold 1\n",
      "Accuracy train:  0.9325\n",
      "training fold 2\n",
      "Accuracy train:  0.9525\n",
      "training fold 3\n",
      "Accuracy train:  0.9325\n",
      "training fold 4\n",
      "Accuracy train:  0.95\n",
      "training fold 5\n",
      "Accuracy train:  0.9675\n",
      "training fold 6\n",
      "Accuracy train:  0.9425\n",
      "training fold 7\n",
      "Accuracy train:  0.9375\n",
      "training fold 8\n",
      "Accuracy train:  0.9375\n",
      "training fold 9\n",
      "Accuracy train:  0.94\n",
      "training fold 10\n",
      "Accuracy train:  0.9325\n",
      "----------------------------------------------------------\n",
      "Summary Training\n",
      "Mean Accuracy train:  0.9625119047619047\n",
      "Mean f1 Train:  0.9633067738166574\n",
      "(28625,)\n",
      "(28625,)\n",
      "----------------------------------------------------------\n",
      "Summary Testing\n",
      " Accuracy test:  0.6050305676855895\n",
      " f1 test:  0.5483381271971876\n",
      "----------------------------------------------------------\n",
      "components 4\n",
      "71\n",
      "training fold 1\n",
      "Accuracy train:  0.99\n",
      "training fold 2\n",
      "Accuracy train:  0.96\n",
      "training fold 3\n",
      "Accuracy train:  1.0\n",
      "training fold 4\n",
      "Accuracy train:  0.98\n",
      "training fold 5\n",
      "Accuracy train:  0.99\n",
      "training fold 6\n",
      "Accuracy train:  0.99\n",
      "training fold 7\n",
      "Accuracy train:  0.99\n",
      "training fold 8\n",
      "Accuracy train:  0.99\n",
      "training fold 9\n",
      "Accuracy train:  0.98\n",
      "training fold 10\n",
      "Accuracy train:  0.97\n",
      "----------------------------------------------------------\n",
      "Summary Training\n",
      "Mean Accuracy train:  0.9634886363636364\n",
      "Mean f1 Train:  0.964246207824652\n",
      "(28625,)\n",
      "(28625,)\n",
      "----------------------------------------------------------\n",
      "Summary Testing\n",
      " Accuracy test:  0.6543231441048035\n",
      " f1 test:  0.6744101872264815\n",
      "----------------------------------------------------------\n",
      "components 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "training fold 1\n",
      "Accuracy train:  0.975\n",
      "training fold 2\n",
      "Accuracy train:  0.995\n",
      "training fold 3\n",
      "Accuracy train:  0.99\n",
      "training fold 4\n",
      "Accuracy train:  0.985\n",
      "training fold 5\n",
      "Accuracy train:  0.98\n",
      "training fold 6\n",
      "Accuracy train:  0.97\n",
      "training fold 7\n",
      "Accuracy train:  0.985\n",
      "training fold 8\n",
      "Accuracy train:  1.0\n",
      "training fold 9\n",
      "Accuracy train:  0.995\n",
      "training fold 10\n",
      "Accuracy train:  0.995\n",
      "----------------------------------------------------------\n",
      "Summary Training\n",
      "Mean Accuracy train:  0.9645108695652176\n",
      "Mean f1 Train:  0.9652461110297212\n",
      "(28625,)\n",
      "(28625,)\n",
      "----------------------------------------------------------\n",
      "Summary Testing\n",
      " Accuracy test:  0.6425152838427948\n",
      " f1 test:  0.667230333972879\n",
      "----------------------------------------------------------\n",
      "components 4\n",
      "71\n",
      "training fold 1\n",
      "Accuracy train:  0.9875\n",
      "training fold 2\n",
      "Accuracy train:  0.99\n",
      "training fold 3\n",
      "Accuracy train:  0.9675\n",
      "training fold 4\n",
      "Accuracy train:  0.9925\n",
      "training fold 5\n",
      "Accuracy train:  0.99\n",
      "training fold 6\n",
      "Accuracy train:  0.99\n",
      "training fold 7\n",
      "Accuracy train:  0.9875\n",
      "training fold 8\n",
      "Accuracy train:  0.9775\n",
      "training fold 9\n",
      "Accuracy train:  0.98\n",
      "training fold 10\n",
      "Accuracy train:  0.9775\n",
      "----------------------------------------------------------\n",
      "Summary Training\n",
      "Mean Accuracy train:  0.9653229166666667\n",
      "Mean f1 Train:  0.9660452905709201\n",
      "(28625,)\n",
      "(28625,)\n",
      "----------------------------------------------------------\n",
      "Summary Testing\n",
      " Accuracy test:  0.65282096069869\n",
      " f1 test:  0.6882293888819174\n",
      "----------------------------------------------------------\n",
      "components 6\n",
      "71\n",
      "training fold 1\n",
      "Accuracy train:  0.99\n",
      "training fold 2\n",
      "Accuracy train:  0.96\n",
      "training fold 3\n",
      "Accuracy train:  1.0\n",
      "training fold 4\n",
      "Accuracy train:  0.98\n",
      "training fold 5\n",
      "Accuracy train:  0.99\n",
      "training fold 6\n",
      "Accuracy train:  0.99\n",
      "training fold 7\n",
      "Accuracy train:  0.99\n",
      "training fold 8\n",
      "Accuracy train:  0.99\n",
      "training fold 9\n",
      "Accuracy train:  0.99\n",
      "training fold 10\n",
      "Accuracy train:  0.98\n",
      "----------------------------------------------------------\n",
      "Summary Training\n",
      "Mean Accuracy train:  0.96615\n",
      "Mean f1 Train:  0.9668441264745259\n",
      "(28625,)\n",
      "(28625,)\n",
      "----------------------------------------------------------\n",
      "Summary Testing\n",
      " Accuracy test:  0.6377991266375546\n",
      " f1 test:  0.642112530203659\n",
      "----------------------------------------------------------\n",
      "components 6\n",
      "71\n",
      "training fold 1\n",
      "Accuracy train:  0.97\n",
      "training fold 2\n",
      "Accuracy train:  0.995\n",
      "training fold 3\n",
      "Accuracy train:  0.99\n",
      "training fold 4\n",
      "Accuracy train:  0.985\n",
      "training fold 5\n",
      "Accuracy train:  0.98\n",
      "training fold 6\n",
      "Accuracy train:  0.97\n",
      "training fold 7\n",
      "Accuracy train:  0.985\n",
      "training fold 8\n",
      "Accuracy train:  1.0\n",
      "training fold 9\n",
      "Accuracy train:  0.99\n",
      "training fold 10\n",
      "Accuracy train:  0.995\n",
      "----------------------------------------------------------\n",
      "Summary Training\n",
      "Mean Accuracy train:  0.9669134615384617\n",
      "Mean f1 Train:  0.9675915753521769\n",
      "(28625,)\n",
      "(28625,)\n",
      "----------------------------------------------------------\n",
      "Summary Testing\n",
      " Accuracy test:  0.6258515283842795\n",
      " f1 test:  0.6338962193204348\n",
      "----------------------------------------------------------\n",
      "components 6\n"
     ]
    }
   ],
   "source": [
    "Cvalue = 100\n",
    "plot = False\n",
    "basicLR_stats_acc = []\n",
    "basicLR_stats_f1 = []\n",
    "res = []\n",
    "for k in [1, 2, 3]:\n",
    "    print('kernel '+str(k))\n",
    "    for components in [2, 4, 6, 8, 10, 12]:\n",
    "        for size in[1000, 2000, 4000]:\n",
    "            print('components '+str(components))\n",
    "            dataTrain = pd.read_csv(fileTrain)\n",
    "            dataTest = pd.read_csv(fileTest)\n",
    "            print(len(dataTrain.columns)) \n",
    "            try:\n",
    "                dataTrain = dataTrain.loc[:, ~dataTrain.columns.str.contains('^Unnamed')]\n",
    "                dataTrain =  dataTrain.drop(['Pred', 'Pred2', 'h', 'e', 'u','ID'], axis = 1)\n",
    "                dataTrain = dataTrain.loc[:, (dataTrain != dataTrain.iloc[0]).any()]\n",
    "                dataTest = dataTest[list(dataTrain.columns)]\n",
    "\n",
    "            except:\n",
    "                print('---')\n",
    "            dataTrain = ut.downSampling(dataTrain)\n",
    "            try:\n",
    "                dataTrain = dataTrain.sample(size, random_state = 0)\n",
    "            except:\n",
    "                print('sample bigger that population')\n",
    "            yTrain = 1*(dataTrain['label'] == 'ClassA')\n",
    "            yTestHO = 1*(dataTest['label'] == 'ClassA')\n",
    "            del dataTrain['label']\n",
    "            del dataTest['label']\n",
    "\n",
    "            names = dataTrain.columns\n",
    "            scaler = preprocessing.StandardScaler()\n",
    "            dataTrain = scaler.fit_transform(dataTrain)\n",
    "            dataTrain = pd.DataFrame(dataTrain, columns=names)\n",
    "\n",
    "            dataTest = scaler.fit_transform(dataTest)\n",
    "            dataTest = pd.DataFrame(dataTest, columns=names)\n",
    "\n",
    "\n",
    "            pca = PCA(n_components=components)\n",
    "            pca.fit(dataTrain)\n",
    "            dataTrain = pca.transform(dataTrain)\n",
    "            dataTrain = pd.DataFrame(dataTrain)\n",
    "            dataTrain = ut.Polinomial(dataTrain,k)\n",
    "\n",
    "\n",
    "            pca.fit(dataTest)\n",
    "            dataTest = pca.transform(dataTest)\n",
    "            dataTest = pd.DataFrame(dataTest)\n",
    "            dataTest = ut.Polinomial(dataTest,k)\n",
    "            #size = dataTrain.shape[0]\n",
    "\n",
    "            start_1 = timeit.default_timer()\n",
    "            skf = StratifiedKFold(n_splits=int(10))\n",
    "            skf.get_n_splits(dataTrain, yTrain)\n",
    "            acc_kfold_Train = []\n",
    "            f1_kfold_Train = []\n",
    "            i = 0\n",
    "\n",
    "            for train_index, test_index in skf.split(dataTrain, yTrain):\n",
    "                        i = i+1\n",
    "                        print('training fold ' + str(i))\n",
    "                        X_train, X_test = dataTrain.iloc[train_index,:], dataTrain.iloc[test_index,:]\n",
    "                        y_train, y_test = yTrain.iloc[train_index], yTrain.iloc[test_index]\n",
    "\n",
    "                        basicLR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial',\n",
    "                                                     C=Cvalue).fit(X_train, y_train)\n",
    "                        predictions_1_Train = basicLR.predict(X_test)\n",
    "\n",
    "                        accTrain = accuracy_score(y_test, predictions_1_Train, normalize=True)\n",
    "                        f1Train = f1_score(y_test, predictions_1_Train, pos_label = 1)\n",
    "\n",
    "                        if plot:\n",
    "                            cm = confusion_matrix(y_test, predictions_1_Train)\n",
    "                            ut.plot_confusion_matrix(cm, ['all', 'rrlyr'], type = 'train')\n",
    "                        print('Accuracy train: ', accTrain)\n",
    "                        #print('Accuracy f1 Train: ', f1Train)\n",
    "                        basicLR_stats_acc.append(accTrain)\n",
    "                        basicLR_stats_f1.append(f1Train)\n",
    "            accTrain = np.mean(basicLR_stats_acc)\n",
    "            f1Train =np.mean(basicLR_stats_f1)\n",
    "            print('----------------------------------------------------------')\n",
    "            print('Summary Training')\n",
    "            print('Mean Accuracy train: ', accTrain)\n",
    "            print('Mean f1 Train: ', f1Train)\n",
    "            stop_1 = timeit.default_timer()\n",
    "            time_CV = stop_1 - start_1\n",
    "            basicLR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial', C=Cvalue).fit(dataTrain, yTrain)\n",
    "            predictions_1_Test = basicLR.predict(dataTest)\n",
    "            print(predictions_1_Test.shape)\n",
    "            print(yTestHO.shape)\n",
    "            print('----------------------------------------------------------')\n",
    "            print('Summary Testing')\n",
    "            accTest = accuracy_score(yTestHO, predictions_1_Test, normalize=True)\n",
    "            f1Test = f1_score(yTestHO, predictions_1_Test,pos_label = 1)\n",
    "            if plot: \n",
    "                cm = confusion_matrix(yTestHO, predictions_1_Test)\n",
    "                ut.plot_confusion_matrix(cm, ['all', 'rrlyr'], type = 'train')\n",
    "\n",
    "            print(' Accuracy test: ', accTest)\n",
    "            print(' f1 test: ', f1Test)\n",
    "            print('----------------------------------------------------------')\n",
    "\n",
    "            res.append([k, components, size,  accTrain, accTest, f1Train, f1Test])\n",
    "            pd.DataFrame(res).to_csv(str(number)+'-BasicCV0707C'+str(Cvalue)+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Logistic Regresion (Polynomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = False\n",
    "basicLR_stats_acc = []\n",
    "basicLR_stats_f1 = []\n",
    "res = []\n",
    "for k in [1, 2, 3]:\n",
    "    print('kernel '+str(k))\n",
    "    for components in [2, 4, 6, 8, 10, 12]:\n",
    "        for size in[1000, 2000, 4000]:\n",
    "            print('components '+str(components))\n",
    "            dataTrain = pd.read_csv(fileTrain)\n",
    "            dataTest = pd.read_csv(fileTest)\n",
    "            print(len(dataTrain.columns)) \n",
    "            try:\n",
    "                dataTrain = dataTrain.loc[:, ~dataTrain.columns.str.contains('^Unnamed')]\n",
    "                dataTrain =  dataTrain.drop(['Pred', 'Pred2', 'h', 'e', 'u','ID'], axis = 1)\n",
    "                dataTrain = dataTrain.loc[:, (dataTrain != dataTrain.iloc[0]).any()]\n",
    "                dataTest = dataTest[list(dataTrain.columns)]\n",
    "\n",
    "            except:\n",
    "                print('---')\n",
    "            dataTrain = ut.downSampling(dataTrain)\n",
    "            try:\n",
    "                dataTrain = dataTrain.sample(size, random_state = 0)\n",
    "            except:\n",
    "                print('sample bigger that population')\n",
    "            yTrain = 1*(dataTrain['label'] == 'ClassA')\n",
    "            yTestHO = 1*(dataTest['label'] == 'ClassA')\n",
    "            del dataTrain['label']\n",
    "            del dataTest['label']\n",
    "\n",
    "            names = dataTrain.columns\n",
    "            scaler = preprocessing.StandardScaler()\n",
    "            dataTrain = scaler.fit_transform(dataTrain)\n",
    "            dataTrain = pd.DataFrame(dataTrain, columns=names)\n",
    "\n",
    "            dataTest = scaler.fit_transform(dataTest)\n",
    "            dataTest = pd.DataFrame(dataTest, columns=names)\n",
    "\n",
    "\n",
    "            pca = PCA(n_components=components)\n",
    "            pca.fit(dataTrain)\n",
    "            dataTrain = pca.transform(dataTrain)\n",
    "            dataTrain = pd.DataFrame(dataTrain)\n",
    "            dataTrain = ut.Polinomial(dataTrain,k)\n",
    "\n",
    "\n",
    "            pca.fit(dataTest)\n",
    "            dataTest = pca.transform(dataTest)\n",
    "            dataTest = pd.DataFrame(dataTest)\n",
    "            dataTest = ut.Polinomial(dataTest,k)\n",
    "            #size = dataTrain.shape[0]\n",
    "\n",
    "            start_1 = timeit.default_timer()\n",
    "            skf = StratifiedKFold(n_splits=int(10))\n",
    "            skf.get_n_splits(dataTrain, yTrain)\n",
    "            acc_kfold_Train = []\n",
    "            f1_kfold_Train = []\n",
    "            i = 0\n",
    "\n",
    "            for train_index, test_index in skf.split(dataTrain, yTrain):\n",
    "                        i = i+1\n",
    "                        print('training fold ' + str(i))\n",
    "                        X_train, X_test = dataTrain.iloc[train_index,:], dataTrain.iloc[test_index,:]\n",
    "                        y_train, y_test = yTrain.iloc[train_index], yTrain.iloc[test_index]\n",
    "\n",
    "                        basicLR = LogisticRegression(penalty='none', solver ='saga').fit(X_train, y_train)\n",
    "                        predictions_1_Train = basicLR.predict(X_test)\n",
    "\n",
    "                        accTrain = accuracy_score(y_test, predictions_1_Train, normalize=True)\n",
    "                        f1Train = f1_score(y_test, predictions_1_Train, pos_label = 1)\n",
    "\n",
    "                        if plot:\n",
    "                            cm = confusion_matrix(y_test, predictions_1_Train)\n",
    "                            ut.plot_confusion_matrix(cm, ['all', 'rrlyr'], type = 'train')\n",
    "                        print('Accuracy train: ', accTrain)\n",
    "                        #print('Accuracy f1 Train: ', f1Train)\n",
    "                        basicLR_stats_acc.append(accTrain)\n",
    "                        basicLR_stats_f1.append(f1Train)\n",
    "            accTrain = np.mean(basicLR_stats_acc)\n",
    "            f1Train =np.mean(basicLR_stats_f1)\n",
    "            print('----------------------------------------------------------')\n",
    "            print('Summary Training')\n",
    "            print('Mean Accuracy train: ', accTrain)\n",
    "            print('Mean f1 Train: ', f1Train)\n",
    "            stop_1 = timeit.default_timer()\n",
    "            time_CV = stop_1 - start_1\n",
    "            basicLR = LogisticRegression(penalty='none', solver ='saga').fit(dataTrain, yTrain)\n",
    "            predictions_1_Test = basicLR.predict(dataTest)\n",
    "            print(predictions_1_Test.shape)\n",
    "            print(yTestHO.shape)\n",
    "            print('----------------------------------------------------------')\n",
    "            print('Summary Testing')\n",
    "            accTest = accuracy_score(yTestHO, predictions_1_Test, normalize=True)\n",
    "            f1Test = f1_score(yTestHO, predictions_1_Test,pos_label = 1)\n",
    "            if plot: \n",
    "                cm = confusion_matrix(yTestHO, predictions_1_Test)\n",
    "                ut.plot_confusion_matrix(cm, ['all', 'rrlyr'], type = 'train')\n",
    "\n",
    "            print(' Accuracy test: ', accTest)\n",
    "            print(' f1 test: ', f1Test)\n",
    "            print('----------------------------------------------------------')\n",
    "\n",
    "            res.append([k, components, size,  accTrain, accTest, f1Train, f1Test])\n",
    "            pd.DataFrame(res).to_csv('BasicCVAllDatawhitoutpenalty-0707'+str(number)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
