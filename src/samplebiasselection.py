# -*- coding: utf-8 -*-
"""SampleBiasSelection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19Wrqvpv-Jm97cw5HzLD7SAcX2rsolf9X
"""

# %matplotlib inline
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.model_selection import LeaveOneOut
from sklearn.ensemble import RandomForestClassifier
import  sklearn.linear_model as linearModel
from sklearn.decomposition import PCA
from sklearn import preprocessing
import numpy as np
import seaborn
import matplotlib.pyplot as plt
from warnings import filterwarnings
filterwarnings('ignore')
import timeit
import pymc3 as pm
import matplotlib.lines as mlines
from sklearn import svm
np.random.seed(1)
from itertools import product, combinations
import sys

sys.path.insert(0,'./src')
import bridgeSampling as bs # it contains a method to estimate the marginal likelihood according to the Bridge Sampling approach
import utilFunctions as ut          # it has different methods to handle and plot data
import BayesianModels as bm # it has methods to build and train bayesian model (Logistic Regression and Neural Nets)
import experiments as exp


def sampleBiasSelection(Data, name = 'rrlyrae', **kwargs):

    Data = Data[(Data[kwargs['name_class_col']] == kwargs['class_1']) |
          (Data[kwargs['name_class_col']] == kwargs['class_2'])]

    label = 1*(Data[kwargs['name_class_col']] == kwargs['class_1'])
    DataBiased = Data.copy()

    del DataBiased[kwargs['name_class_col']]
    del DataBiased[kwargs['id_col']]

    clf = RandomForestClassifier(max_depth=int(kwargs['deep_Max']), random_state=0)

    try:
        DataBiased = DataBiased.replace('\n', '', regex = True).replace('null', '0.0', regex = True).apply(pd.to_numeric, errors ='ignore')
    except:
        print('Error in replace')

    clf.fit(DataBiased, label)

    Pred2 =  clf.predict_proba(DataBiased)
    Pred =  clf.predict(DataBiased)
    print('Acc:', accuracy_score(Pred, label))
    cm = confusion_matrix(Pred, label)
    ut.plot_confusion_matrix(cm, ['all', name])

    Data['Pred'] = Pred2[:,0].tolist()
    Data['Pred2'] = Pred2[:,1].tolist()

    Data['h'] = 1 -  Data['Pred']*Data['Pred'] - Data['Pred2']*Data['Pred2']
    t = float(kwargs['T'])
    factor = t*Data['h']
    Data['e'] = np.exp(-factor)
    Data['u'] = np.random.uniform(0, 1, Data.shape[0])

    BiasSelection = True
    threshold = 0.8

    if BiasSelection:
        Data_test  = Data[(Data['e']<= Data['u'])]
        Data_train = Data[(Data['e']> Data['u'])]
    else:
        Data_test  = Data[(threshold<= Data['u'])]
        Data_train = Data[(threshold> Data['u'])]


    label_train = Data_train[kwargs['name_class_col']]
    label_test = Data_test[kwargs['name_class_col']]

    filename='Results/plots/'+name+'OGLE.txt'
    f = open(filename, 'w+')
    f.write('TRAIN\n')
    f.write(str(label_train.value_counts())+'\n')
    f.write('TEST\n')
    f.write(str(label_test.value_counts())+'\n')
    f.close()
    del Data_train[kwargs['name_class_col']]
    del Data_test[kwargs['name_class_col']]

    print('Shape training: ', Data_train.shape)
    print('Shape testing: ', Data_test.shape)
    return Data_train, Data_test, label_train, label_test


def plot(train, test, title='RRLYRAE', survey = 'OGLE'):
    x_w = np.empty(train.shape)
    x_w.fill(1/train.shape[0])
    y_w = np.empty(test.shape)
    y_w.fill(1/test.shape[0])
    bins = np.linspace(0, 1, 10)
    plt.hist([train, test], bins, weights=[x_w, y_w], label=['training set', 'testing set'])
    plt.legend(loc='best')
    plt.title(title)
    plt.xlabel('soft predict')
    plt.ylabel('normalized frequency')
    plt.savefig('Results/plots/'+title+survey+'2.png')
    plt.clf()


def export(train, test, name='RRLYRAE', survey = 'OGLE'):
    train.to_csv('data/BIASEDFATS/Train2_'+survey+'_'+name+'.csv')
    test.to_csv('data/BIASEDFATS/Test2_'+survey+'_'+name+'.csv')
